Best config yet (HEX):

64,64,64,64,64 Conv2d
Batch normalization (before activation)
Adam
categorical_crossentropy
relu
learn 0.001
lr scale 0.998
min lr 0.0001
batch size 32
No dropout
kernel_regularizer on every layer except last
Straight to softmax from conv2d (1,(1,1))